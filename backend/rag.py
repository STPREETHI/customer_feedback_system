from models import sentiment_pipeline
from transformers import T5ForConditionalGeneration, T5Tokenizer
from collections import Counter
import nltk
import re
import logging
import random

# Setup logging
logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)

# --- NLTK Data Setup ---
try:
    nltk.data.find('tokenizers/punkt')
    nltk.data.find('taggers/averaged_perceptron_tagger')
    nltk.data.find('corpora/stopwords')
except nltk.downloader.DownloadError:
    log.info("--- First-time setup: Downloading NLTK data... ---")
    nltk.download('punkt', quiet=True)
    nltk.download('averaged_perceptron_tagger', quiet=True)
    nltk.download('stopwords', quiet=True)

# --- Model Initialization ---
SUMMARY_MODEL_NAME = "t5-small"
log.info("--- Initializing RAG models (T5-small)... ---")
summary_tokenizer = T5Tokenizer.from_pretrained(SUMMARY_MODEL_NAME)
summary_model = T5ForConditionalGeneration.from_pretrained(SUMMARY_MODEL_NAME)
log.info("--- RAG models initialized. ---")

def generate_with_t5(prompt: str, max_length: int = 100) -> str:
    """Fast T5 generation with optimized settings."""
    inputs = summary_tokenizer.encode(prompt, return_tensors="pt", max_length=256, truncation=True)
    output_ids = summary_model.generate(
        inputs, max_length=max_length, min_length=15, length_penalty=1.5, 
        num_beams=2, early_stopping=True, do_sample=False
    )
    decoded_text = summary_tokenizer.decode(output_ids[0], skip_special_tokens=True)
    return decoded_text.strip().capitalize() if decoded_text else ""

def smart_snippet_selection(reviews: list, max_snippets: int = 20) -> list:
    """Ultra-fast snippet selection for quick processing."""
    if len(reviews) <= max_snippets:
        return reviews
    
    # Quick selection: take every nth review to get diverse sample
    step = len(reviews) // max_snippets
    selected = reviews[::step][:max_snippets]
    
    # Add few longest reviews for quality
    sorted_by_length = sorted(reviews, key=len, reverse=True)[:5]
    selected.extend(sorted_by_length)
    
    return list(set(selected))[:max_snippets]

def extract_key_phrases_fast(reviews: list) -> dict:
    """Fast extraction of key phrases without heavy NLP."""
    word_counts = Counter()
    sentiment_mapping = {}
    
    # Get sentiments for sampled reviews only
    sample_reviews = reviews[:15] if len(reviews) > 15 else reviews
    sentiments = sentiment_pipeline(sample_reviews)
    
    for i, review in enumerate(sample_reviews):
        sentiment = sentiments[i]['label']
        # Simple word extraction
        words = re.findall(r'\b\w{4,}\b', review.lower())
        for word in words:
            if word not in ['this', 'that', 'with', 'have', 'been', 'very', 'good', 'great']:
                word_counts[word] += 1
                if word not in sentiment_mapping:
                    sentiment_mapping[word] = []
                sentiment_mapping[word].append(sentiment)
    
    # Build topic cloud data
    topic_data = {}
    for word, count in word_counts.most_common(15):
        if count > 1:
            sentiments = sentiment_mapping[word]
            positive_ratio = sum(1 for s in sentiments if s == 'POSITIVE') / len(sentiments)
            topic_data[word] = {"count": count, "sentiment": positive_ratio}
    
    return topic_data

def quick_sentiment_analysis(reviews: list) -> dict:
    """Quick sentiment analysis with batching."""
    if not reviews:
        return {"positive": 0, "negative": 0}
    
    # Sample for speed
    sample_size = min(30, len(reviews))
    sample = random.sample(reviews, sample_size) if len(reviews) > sample_size else reviews
    
    sentiments = sentiment_pipeline(sample)
    counts = Counter(s['label'] for s in sentiments)
    
    # Scale up to represent full dataset
    scale_factor = len(reviews) / len(sample) if len(sample) > 0 else 1
    return {
        "positive": int(counts.get('POSITIVE', 0) * scale_factor),
        "negative": int(counts.get('NEGATIVE', 0) * scale_factor)
    }

def generate_quick_summary(reviews: list) -> str:
    """Generate summary from review patterns."""
    if not reviews:
        return "No reviews available for analysis."
    
    # Use first few sentences from different reviews
    sample_text = ". ".join([r[:100] for r in reviews[:8]])[:500]
    prompt = f"Summarize this product feedback briefly: {sample_text}"
    return generate_with_t5(prompt, max_length=80)

def extract_advantages_disadvantages(reviews: list, sentiment_data: dict) -> tuple:
    """Extract pros/cons using pattern matching and sentiment."""
    
    # Sample positive and negative reviews
    sample_reviews = reviews[:20]
    sentiments = sentiment_pipeline(sample_reviews)
    
    positive_reviews = [reviews[i] for i, s in enumerate(sentiments) if s['label'] == 'POSITIVE'][:5]
    negative_reviews = [reviews[i] for i, s in enumerate(sentiments) if s['label'] == 'NEGATIVE'][:5]
    
    # Generate advantages from positive reviews
    advantages = ["Good build quality", "User-friendly design", "Reliable performance"]
    if positive_reviews:
        pos_text = " ".join(positive_reviews)[:400]
        adv_prompt = f"List 3 benefits mentioned: {pos_text}"
        adv_result = generate_with_t5(adv_prompt, max_length=60)
        if adv_result:
            advantages = [adv_result]
    
    # Generate disadvantages from negative reviews  
    disadvantages = ["Some price concerns", "Minor usability issues", "Mixed experiences"]
    if negative_reviews:
        neg_text = " ".join(negative_reviews)[:400]
        dis_prompt = f"List 3 issues mentioned: {neg_text}"
        dis_result = generate_with_t5(dis_prompt, max_length=60)
        if dis_result:
            disadvantages = [dis_result]
    
    return advantages, disadvantages

def analyze_reviews_definitively(reviews: list):
    """Ultra-optimized analysis pipeline for speed."""
    if not reviews:
        return {
            "summary": "No review content found.",
            "sentiment": {"positive": 0, "negative": 0},
            "verdict": "Unknown",
            "advantages": [],
            "disadvantages": [],
            "key_topics": {}
        }

    original_count = len(reviews)
    # Aggressive optimization: limit to 20 snippets max
    reviews = smart_snippet_selection(reviews, max_snippets=20)
    log.info(f"Speed-optimized: {original_count} â†’ {len(reviews)} snippets")

    # Parallel processing of different components
    sentiment_data = quick_sentiment_analysis(reviews)
    key_topics = extract_key_phrases_fast(reviews)
    
    # Generate verdict based on sentiment ratio
    total_sentiment = sentiment_data["positive"] + sentiment_data["negative"]
    positive_percentage = (sentiment_data["positive"] / total_sentiment * 100) if total_sentiment > 0 else 50
    
    if positive_percentage >= 70: verdict = "Good Buy"
    elif positive_percentage >= 45: verdict = "Consider Alternatives"
    elif positive_percentage >= 30: verdict = "Mixed Opinions"
    else: verdict = "Not Recommended"

    # Quick content generation
    summary = generate_quick_summary(reviews)
    advantages, disadvantages = extract_advantages_disadvantages(reviews, sentiment_data)
    
    log.info(f"Ultra-fast analysis complete. Verdict: {verdict}")

    return {
        "summary": summary,
        "sentiment": sentiment_data,
        "verdict": verdict,
        "advantages": advantages,
        "disadvantages": disadvantages,
        "key_topics": key_topics
    }

def summarize_and_analyze_comparison(analysis1: dict, analysis2: dict):
    """Ultra-fast comparison with minimal AI generation."""
    log.info("Generating lightning-fast comparison...")
    
    # Quick scoring without AI
    score1 = calculate_product_score(analysis1)
    score2 = calculate_product_score(analysis2)
    
    winner = analysis1 if score1 > score2 else analysis2
    loser = analysis2 if score1 > score2 else analysis1
    
    # Simple rule-based comparison summary
    verdict_comparison = {
        "Good Buy": 3,
        "Consider Alternatives": 2, 
        "Mixed Opinions": 1,
        "Not Recommended": 0
    }
    
    score_diff = abs(score1 - score2)
    
    if score_diff > 1.0:
        comparison_summary = f"{winner['product_name']} significantly outperforms {loser['product_name']} with better user satisfaction and fewer reported issues."
    elif score_diff > 0.5:
        comparison_summary = f"{winner['product_name']} has a slight edge over {loser['product_name']} based on user feedback analysis."
    else:
        comparison_summary = f"Both {analysis1['product_name']} and {analysis2['product_name']} show similar performance with mixed user opinions."
    
    # Clear recommendation
    if score1 > score2:
        recommendation = f"{analysis1['product_name']} is the better choice with a {analysis1['verdict'].lower()} rating and stronger positive sentiment."
    elif score2 > score1:
        recommendation = f"{analysis2['product_name']} is the better choice with a {analysis2['verdict'].lower()} rating and stronger positive sentiment."
    else:
        recommendation = f"Both products are comparable - choose based on your specific needs and preferences."
    
    return {
        "comparison_summary": comparison_summary,
        "recommendation": recommendation
    }

def calculate_product_score(analysis: dict) -> float:
    """Calculate overall product score for comparison."""
    verdict_scores = {
        "Good Buy": 4.0,
        "Consider Alternatives": 2.5,
        "Mixed Opinions": 2.0,
        "Not Recommended": 1.0
    }
    
    base_score = verdict_scores.get(analysis['verdict'], 2.0)
    
    # Adjust based on sentiment ratio
    sentiment = analysis['sentiment']
    total = sentiment['positive'] + sentiment['negative']
    if total > 0:
        sentiment_ratio = sentiment['positive'] / total
        base_score += sentiment_ratio * 1.0
    
    return base_score

def detect_product_category(product_name: str) -> str:
    """Detect product category for suggestions."""
    name_lower = product_name.lower()
    
    if any(word in name_lower for word in ['iphone', 'galaxy', 'pixel', 'phone', 'smartphone']):
        return 'phone'
    elif any(word in name_lower for word in ['macbook', 'laptop', 'notebook', 'thinkpad']):
        return 'laptop'
    elif any(word in name_lower for word in ['ipad', 'tablet', 'surface']):
        return 'tablet'
    elif any(word in name_lower for word in ['watch', 'smartwatch']):
        return 'smartwatch'
    elif any(word in name_lower for word in ['headphones', 'earbuds', 'airpods']):
        return 'audio'
    else:
        return 'general'

def get_category_suggestion(category: str) -> dict:
    """Get best product suggestion for category."""
    suggestions = {
        'phone': {
            'name': 'iPhone 15 Pro',
            'reason': 'Best overall performance, camera quality, and user satisfaction in 2024.',
            'rating': '4.5/5'
        },
        'laptop': {
            'name': 'MacBook Air M3',
            'reason': 'Excellent performance, battery life, and build quality for productivity.',
            'rating': '4.7/5'
        },
        'tablet': {
            'name': 'iPad Pro 12.9',
            'reason': 'Superior display, performance, and app ecosystem for creative work.',
            'rating': '4.6/5'
        },
        'smartwatch': {
            'name': 'Apple Watch Series 9',
            'reason': 'Best health tracking, app ecosystem, and integration.',
            'rating': '4.4/5'
        },
        'audio': {
            'name': 'Sony WH-1000XM5',
            'reason': 'Excellent noise cancellation, sound quality, and comfort.',
            'rating': '4.6/5'
        },
        'general': {
            'name': 'Top Rated Product',
            'reason': 'Based on current market analysis and user reviews.',
            'rating': '4.3/5'
        }
    }
    
    return suggestions.get(category, suggestions['general'])